{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RhCBt5PzHJ7c","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1756242152425,"user_tz":-60,"elapsed":11050,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}},"outputId":"e3ba274e-da35-40d5-e5bf-6ede713df714"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4071583401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive for persistent storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create directories for results and figures on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["# Mount Google Drive for persistent storage\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","\n","# Create directories for results and figures on Google Drive\n","results_base_dir = '/content/drive/MyDrive/Colab_Notebooks/Fashion_MNIST/Classification/'\n","figures_base_dir_original = '/content/drive/MyDrive/Colab_Notebooks/Fashion_MNIST/Classification/Baseline_100p/'\n","import os\n","os.makedirs(results_base_dir, exist_ok=True)\n","os.makedirs(figures_base_dir_original, exist_ok=True)\n","\n","# Set environment variables (optional, adjust if needed)\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".9\"\n","\n","# Load packages\n","import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","import jax\n","import jax.numpy as jnp\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import csv\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab_Notebooks/Fashion_MNIST/Classification/') # Adjust this path if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAONimuxWD_H","executionInfo":{"status":"aborted","timestamp":1756242152461,"user_tz":-60,"elapsed":56,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"outputs":[],"source":["csv_filename_orth = os.path.join(results_base_dir, 'C_orth_fMNIST.csv')\n","csv_filename_eval = os.path.join(results_base_dir, 'C_eval_fMNIST.csv')\n","csv_filename_zero = os.path.join(results_base_dir, 'C_zero_fMNIST.csv')\n","\n","number_of_simulations = 5\n","\n","columns = [\n","    \"P_training(%)\", \"Training Set\", \"Test set\", \"Epoch\",\n","    \"Total_Loss_Training\", \"BCE_Training\", \"KLD_Training\", \"LL_Training\",\n","    \"Total_Loss_Test\", \"BCE_Test\", \"KLD_Test\", \"LL_Test\",\n","    \"Train_accuracy\", \"Test_Accuracy_Original\",\n","    \"Accuracy_Original_Top_Generated_Bottom\",\n","    \"Accuracy_Generated_Top_Original_Bottom\",\n","    \"Accuracy_Processed_Top_Processed_Bottom\",\n","    \"AU1\", \"AU2\"\n","]\n"]},{"cell_type":"code","source":["def read_and_aggregate(csv_path, method_name, n_per_group):\n","\n","    df = pd.read_csv(csv_path, header=None, skiprows=1)\n","    df.columns = columns\n","    # Chunk into groups and compute mean/std\n","    means, stds, pcts = [], [], []\n","    for i in range(0, len(df), n_per_group):\n","        block = df.iloc[i:i+n_per_group]\n","        if block.empty:\n","            continue\n","        pcts.append(block.iloc[0][\"P_training(%)\"])\n","        means.append(block.mean(axis=0))\n","        stds.append(block.std(axis=0))\n","\n","    mean_df = pd.DataFrame(means).reset_index(drop=True)\n","    std_df  = pd.DataFrame(stds).reset_index(drop=True)\n","\n","    # Preserve integer-like percentages and tag method\n","    mean_df[\"P_training(%)\"] = pd.Series(pcts).astype(int)\n","    std_df[\"P_training(%)\"]  = pd.Series(pcts).astype(int)\n","    mean_df[\"method\"] = method_name\n","    std_df[\"method\"]  = method_name\n","\n","    return mean_df, std_df"],"metadata":{"id":"XnZZ5kSgNioA","executionInfo":{"status":"aborted","timestamp":1756242152462,"user_tz":-60,"elapsed":55,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_df_orth, std_df_orth = read_and_aggregate(csv_filename_orth, \"orth\", number_of_simulations)\n","mean_df_eval, std_df_eval = read_and_aggregate(csv_filename_eval, \"eval\", number_of_simulations)\n","mean_df_zero, std_df_zero = read_and_aggregate(csv_filename_zero, \"zero\", number_of_simulations)"],"metadata":{"id":"dHf1EVUWNz4i","executionInfo":{"status":"aborted","timestamp":1756242152464,"user_tz":-60,"elapsed":56,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_means, all_stds = [], []\n","all_means.append(mean_df_orth)\n","all_means.append(mean_df_eval)\n","all_means.append(mean_df_zero)\n","all_stds.append(std_df_orth)\n","all_stds.append(std_df_eval)\n","all_stds.append(std_df_zero)\n","\n","long_mean = pd.concat(all_means, ignore_index=True)\n","long_std  = pd.concat(all_stds, ignore_index=True)"],"metadata":{"id":"td7AdPKeOX66","executionInfo":{"status":"aborted","timestamp":1756242152465,"user_tz":-60,"elapsed":56,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def line_with_errorbars_by_method(long_mean, long_std, metric, title, ylabel, outfile):\n","    \"\"\"Plot metric vs % training with a line per method; error bars from std.\"\"\"\n","    plt.figure(figsize=(8, 5))\n","\n","    for method, g in long_mean.groupby(\"method\"):\n","        # ensure consistent ordering by percentage\n","        g_sorted = g.sort_values(\"P_training(%)\")\n","        std_sorted = long_std[long_std[\"method\"] == method].sort_values(\"P_training(%)\")\n","\n","        x = g_sorted[\"P_training(%)\"].values\n","        y = g_sorted[metric].values\n","        yerr = std_sorted[metric].values if metric in std_sorted.columns else None\n","\n","        plt.errorbar(x, y, yerr=yerr, fmt='-o', capsize=4, label=method)\n","\n","    plt.xlabel(\"Training set used (%)\")\n","    plt.ylabel(ylabel)\n","    #plt.title(title)\n","    plt.legend(title=\"Method\")\n","    plt.tight_layout()\n","    plt.savefig(outfile, dpi=200)\n","    plt.close()"],"metadata":{"id":"Ot52yQ4POkgL","executionInfo":{"status":"aborted","timestamp":1756242152466,"user_tz":-60,"elapsed":56,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"Test_Accuracy_Original\",\n","                                  title=\"Test Accuracy (Original Views) vs Training %\",\n","                                  ylabel=\"Accuracy\",\n","                                  outfile=os.path.join(figures_base_dir_original, 'acc_original_vs_pct.png'))\n","\n","line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"Accuracy_Original_Top_Generated_Bottom\",\n","                                  title=\"Accuracy (Original Top / Generated Bottom) vs Training %\",\n","                                  ylabel=\"Accuracy\",\n","                                  outfile=os.path.join(figures_base_dir_original, 'acc_origTop_genBottom_vs_pct.png'))\n","\n","line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"Accuracy_Processed_Top_Processed_Bottom\",\n","                                  title=\"Accuracy (Processed Top & Bottom) vs Training %\",\n","                                  ylabel=\"Accuracy\",\n","                                  outfile=os.path.join(figures_base_dir_original, 'acc_processed_vs_pct.png'))"],"metadata":{"id":"a5z7UzGxOq5c","executionInfo":{"status":"aborted","timestamp":1756242152467,"user_tz":-60,"elapsed":11127,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"BCE_Test\",\n","                                  title=\"BCE_Test vs Training %\",\n","                                  ylabel=\"BCE_Test\",\n","                                  outfile=os.path.join(figures_base_dir_original, \"bce_vs_pct.png\"))\n","\n","line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"LL_Test\",\n","                                  title=\"Log-Likelihood (Test) vs Training %\",\n","                                  ylabel=\"LL_Test\",\n","                                  outfile=os.path.join(figures_base_dir_original, \"ll_vs_pct.png\"))\n","\n","line_with_errorbars_by_method(long_mean, long_std,\n","                                  metric=\"KLD_Test\",\n","                                  title=\"KLD_Test vs Training %\",\n","                                  ylabel=\"KLD_Test\",\n","                                  outfile=os.path.join(figures_base_dir_original, \"kld_vs_pct.png\"))"],"metadata":{"id":"qbCD5JDzPnIS","executionInfo":{"status":"aborted","timestamp":1756242152468,"user_tz":-60,"elapsed":11127,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def penalty_vs_pct(long_mean, long_std, acc_col, title, outfile):\n","    \"\"\"\n","    Plot 'imputation penalty' vs % training for each method using each method's\n","    own 100% original baseline. Penalty = baseline_100%_original - accuracy(metric).\n","    Error bars combine baseline and metric std in quadrature.\n","    \"\"\"\n","    plt.figure(figsize=(8, 5))\n","\n","    for method, g in long_mean.groupby(\"method\"):\n","        g_std = long_std[long_std[\"method\"] == method]\n","\n","        # find baseline at 100%\n","        m100 = g[g[\"P_training(%)\"] == 100]\n","        s100 = g_std[g_std[\"P_training(%)\"] == 100]\n","        if m100.empty or s100.empty:\n","            # if missing 100% row, skip\n","            continue\n","\n","        base_mean = float(m100[\"Test_Accuracy_Original\"].values[0])\n","        base_sd   = float(s100[\"Test_Accuracy_Original\"].values[0])\n","\n","        g_sorted = g.sort_values(\"P_training(%)\")\n","        s_sorted = g_std.sort_values(\"P_training(%)\")\n","\n","        x = g_sorted[\"P_training(%)\"].values\n","        y = base_mean - g_sorted[acc_col].values\n","        yerr = np.sqrt(base_sd**2 + (s_sorted[acc_col].values)**2)\n","\n","        plt.errorbar(x, y, yerr=yerr, fmt='-o', capsize=4, label=method)\n","\n","    plt.xlabel(\"Training set used (%)\")\n","    plt.ylabel(\"Accuracy drop vs 100% original\")\n","    #plt.title(title + \" (baseline per method = 100% Test_Accuracy_Original)\")\n","    plt.legend(title=\"Method\")\n","    plt.tight_layout()\n","    plt.savefig(outfile, dpi=200)\n","    plt.close()"],"metadata":{"id":"P5e2EhIzUKSZ","executionInfo":{"status":"aborted","timestamp":1756242152469,"user_tz":-60,"elapsed":11128,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["penalty_vs_pct(long_mean, long_std,\n","                   acc_col=\"Accuracy_Original_Top_Generated_Bottom\",\n","                   title=\"Imputation penalty (Generated Bottom)\",\n","                   outfile=os.path.join(figures_base_dir_original, \"penalty_generated_vs_pct.png\"))\n","\n","penalty_vs_pct(long_mean, long_std,\n","                   acc_col=\"Accuracy_Processed_Top_Processed_Bottom\",\n","                   title=\"Imputation penalty (Processed)\",\n","                   outfile=os.path.join(figures_base_dir_original, \"penalty_processed_vs_pct.png\"))"],"metadata":{"id":"-oJbNW7OUTbm","executionInfo":{"status":"aborted","timestamp":1756242152471,"user_tz":-60,"elapsed":11130,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def latent_capacity_scatter(long_mean, long_std, au_col, acc_col, outfile):\n","    \"\"\"\n","    Scatter: AUx vs accuracy, colored by method (matplotlib default colors).\n","    Points annotated with % training for readability (avoids specifying colors by %).\n","    Adds a simple linear fit per method if possible.\n","    \"\"\"\n","    plt.figure(figsize=(7, 5))\n","\n","    for method, g in long_mean.groupby(\"method\"):\n","        g_sorted = g.sort_values(\"P_training(%)\")\n","\n","        xs = g_sorted[au_col].values\n","        ys = g_sorted[acc_col].values\n","        plt.scatter(xs, ys, label=method, edgecolors='k')\n","\n","        # annotate with percent labels\n","        for _, row in g_sorted.iterrows():\n","            plt.annotate(f\"{int(row['P_training(%)'])}%\", (row[au_col], row[acc_col]),\n","                         textcoords=\"offset points\", xytext=(5,5), fontsize=8)\n","\n","        # optional linear fit if variance exists\n","        if len(xs) >= 2 and np.std(xs) > 0:\n","            m, b = np.polyfit(xs, ys, 1)\n","            xline = np.linspace(xs.min(), xs.max(), 100)\n","            plt.plot(xline, m*xline + b, linestyle='--')\n","\n","    plt.xlabel(au_col)\n","    plt.ylabel(acc_col)\n","    #plt.title(f\"{acc_col} vs {au_col}\")\n","    plt.legend(title=\"Method\")\n","    plt.tight_layout()\n","    plt.savefig(outfile, dpi=200)\n","    plt.close()"],"metadata":{"id":"8SJITpbSUvm8","executionInfo":{"status":"aborted","timestamp":1756242152472,"user_tz":-60,"elapsed":11130,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_capacity_scatter(long_mean, long_std,\n","                            au_col=\"AU1\",\n","                            acc_col=\"Accuracy_Processed_Top_Processed_Bottom\",\n","                            outfile=os.path.join(figures_base_dir_original, \"AU1_vs_acc_processed.png\"))\n","\n","latent_capacity_scatter(long_mean, long_std,\n","                            au_col=\"AU2\",\n","                            acc_col=\"Accuracy_Processed_Top_Processed_Bottom\",\n","                            outfile=os.path.join(figures_base_dir_original, \"AU2_vs_acc_processed.png\"))"],"metadata":{"id":"9bMczH7mU5Iv","executionInfo":{"status":"aborted","timestamp":1756242152473,"user_tz":-60,"elapsed":11131,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def latent_capacity_scatter_sum(long_mean, long_std,\n","                                au_col,            # \"AU1\", \"AU2\", or \"AU1+AU2\" / \"AU_SUM\" / \"AU1_plus_AU2\"\n","                                acc_col,           # e.g. \"Accuracy_Processed_Top_Processed_Bottom\"\n","                                outfile=None,      # filepath or None to just show()\n","                                annotate_pct=True,\n","                                fit_line=True,\n","                                show_errorbars=True):\n","    \"\"\"\n","    Scatter: AUx (or AU1+AU2) vs accuracy, colored by method (matplotlib defaults).\n","    Points annotated with % training. Optional linear fit and error bars.\n","    Expects columns: \"P_training(%)\", \"method\", \"AU1\", \"AU2\", acc_col in long_mean/long_std.\n","    \"\"\"\n","    plt.figure(figsize=(7, 5))\n","\n","    # Normalize alias for AU sum\n","    use_sum = au_col in {\"AU_SUM\", \"AU1+AU2\", \"AU1_plus_AU2\"}\n","\n","    for method, g_mean in long_mean.groupby(\"method\"):\n","        g_mean = g_mean.sort_values(\"P_training(%)\")\n","        g_std  = long_std[long_std[\"method\"] == method].sort_values(\"P_training(%)\")\n","\n","        if use_sum:\n","            xs = (g_mean[\"AU1\"].values + g_mean[\"AU2\"].values).astype(float)\n","            # x-error via quadrature if requested\n","            if show_errorbars:\n","                xerr = np.sqrt(g_std[\"AU1\"].values.astype(float)**2 +\n","                               g_std[\"AU2\"].values.astype(float)**2)\n","            x_label = \"AU1+AU2\"\n","        else:\n","            xs = g_mean[au_col].values.astype(float)\n","            xerr = g_std[au_col].values.astype(float) if show_errorbars and (au_col in g_std.columns) else None\n","            x_label = au_col\n","\n","        ys = g_mean[acc_col].values.astype(float)\n","        yerr = g_std[acc_col].values.astype(float) if show_errorbars and (acc_col in g_std.columns) else None\n","\n","        # scatter points (default colors)\n","        plt.scatter(xs, ys, label=method, edgecolors='k')\n","\n","        # optional error bars\n","        #if show_errorbars:\n","        #    plt.errorbar(xs, ys, xerr=xerr, yerr=yerr, fmt='none', ecolor='gray', alpha=0.6, capsize=3)\n","\n","        # annotate with % training\n","        if annotate_pct:\n","            for _, row in g_mean.iterrows():\n","                xv = (float(row[\"AU1\"] + row[\"AU2\"])) if use_sum else float(row[au_col])\n","                yv = float(row[acc_col])\n","                plt.annotate(f\"{int(row['P_training(%)'])}%\", (xv, yv),\n","                             textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n","\n","        # optional linear fit\n","        if fit_line and len(xs) >= 2 and np.std(xs) > 0:\n","            m, b = np.polyfit(xs, ys, 1)\n","            xline = np.linspace(xs.min(), xs.max(), 100)\n","            plt.plot(xline, m * xline + b, linestyle='--')\n","\n","    plt.xlabel(x_label)\n","    plt.ylabel(acc_col)\n","    #plt.title(f\"{acc_col} vs {x_label}\")\n","    plt.legend(title=\"Method\")\n","    plt.tight_layout()\n","\n","    if outfile:\n","        plt.savefig(outfile, dpi=200)\n","        plt.close()\n","    else:\n","        plt.show()"],"metadata":{"id":"uNu5g0RIWpd2","executionInfo":{"status":"aborted","timestamp":1756242152474,"user_tz":-60,"elapsed":11132,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_capacity_scatter_sum(long_mean, long_std,\n","                        au_col=\"AU1+AU2\",\n","                        acc_col=\"Accuracy_Processed_Top_Processed_Bottom\",\n","                        outfile=os.path.join(figures_base_dir_original,\"AU1plusAU2_vs_acc_processed.png\"))"],"metadata":{"id":"S6DnQOnDW2mL","executionInfo":{"status":"aborted","timestamp":1756242152475,"user_tz":-60,"elapsed":11133,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["percentages = sorted([int(p) for p in mean_df_orth[\"P_training(%)\"]])\n","# --- 3) Build grouped bar chart: x-axis = view combinations; bars = percentages ---\n","view_cols = [\n","    \"Test_Accuracy_Original\",\n","    \"Accuracy_Original_Top_Generated_Bottom\",\n","    \"Accuracy_Generated_Top_Original_Bottom\",\n","    \"Accuracy_Processed_Top_Processed_Bottom\"\n","]\n","\n","x = np.arange(len(view_cols))                  # positions for the three view combos\n","nP = len(percentages)\n","bar_width = 0.8 / nP                           # fit all % bars within each category\n","\n","# Choose your processed case (the \"fourth case\" you mentioned)\n","processed_col = \"Accuracy_Processed_Top_Processed_Bottom\"\n","proc_idx = view_cols.index(processed_col)  # index within view_cols\n","\n","# Use the same viridis style, but sized to however many percentages you have\n","viridis = plt.cm.get_cmap('viridis', max(nP, 3))   # at least 3, but 4 if you have 4 percentages\n","colors = viridis(np.linspace(0, 1, nP))            # or use jnp.linspace if you prefer\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","for i, p in enumerate(percentages):\n","    y = [float(mean_df_orth.loc[mean_df_orth[\"P_training(%)\"] == p, col].values[0])\n","         for col in view_cols]\n","    yerr = [float(std_df_orth.loc[std_df_orth[\"P_training(%)\"] == p, col].values[0])\n","            for col in view_cols]\n","\n","    offset = (i - (nP - 1) / 2) * bar_width\n","    bars = ax.bar(x + offset, y, yerr=yerr, capsize=5, width=bar_width, label=f\"{p}%\", color=colors[i])\n","\n","    proc_bar = bars[proc_idx]\n","    height = proc_bar.get_height()\n","    ax.text(proc_bar.get_x(), height,\n","            f\"{height:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n","\n","ax.set_xticks(x)\n","\n","index_labels_plot2 = [\n","    \"Full_test_original_images\",\n","    \"Top_Original_Bottom_Generated\",\n","    \"Top_Generated_Bottom_Original\",\n","    \"Top_Processed_Bottom_Processed\"\n","]\n","ax.set_xticklabels(index_labels_plot2, rotation=5, ha='center')\n","ax.set_ylabel(\"Accuracy\")\n","ax.set_title(\"Classifier Accuracies by View Combination vs Training Percentage for $\\mathbf{C}^T\\mathbf{C}=\\mathbf{C}\\mathbf{C}^T=\\mathbf{I}$\")\n","ax.legend(title=\"Training %\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(figures_base_dir_original, 'accuracy_comparison_orth.png'))\n","plt.show()"],"metadata":{"id":"mUZHzKr_OdtG","executionInfo":{"status":"aborted","timestamp":1756242152476,"user_tz":-60,"elapsed":11132,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["percentages = sorted([int(p) for p in mean_df_eval[\"P_training(%)\"]])\n","# --- 3) Build grouped bar chart: x-axis = view combinations; bars = percentages ---\n","view_cols = [\n","    \"Test_Accuracy_Original\",\n","    \"Accuracy_Original_Top_Generated_Bottom\",\n","    \"Accuracy_Generated_Top_Original_Bottom\",\n","    \"Accuracy_Processed_Top_Processed_Bottom\"\n","]\n","\n","x = np.arange(len(view_cols))                  # positions for the three view combos\n","nP = len(percentages)\n","bar_width = 0.8 / nP                           # fit all % bars within each category\n","\n","# Choose your processed case (the \"fourth case\" you mentioned)\n","processed_col = \"Accuracy_Processed_Top_Processed_Bottom\"\n","proc_idx = view_cols.index(processed_col)  # index within view_cols\n","\n","# Use the same viridis style, but sized to however many percentages you have\n","viridis = plt.cm.get_cmap('viridis', max(nP, 3))   # at least 3, but 4 if you have 4 percentages\n","colors = viridis(np.linspace(0, 1, nP))            # or use jnp.linspace if you prefer\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","for i, p in enumerate(percentages):\n","    y = [float(mean_df_eval.loc[mean_df_eval[\"P_training(%)\"] == p, col].values[0])\n","         for col in view_cols]\n","    yerr = [float(std_df_eval.loc[std_df_eval[\"P_training(%)\"] == p, col].values[0])\n","            for col in view_cols]\n","\n","    offset = (i - (nP - 1) / 2) * bar_width\n","    bars = ax.bar(x + offset, y, yerr=yerr, capsize=5, width=bar_width, label=f\"{p}%\", color=colors[i])\n","\n","    proc_bar = bars[proc_idx]\n","    height = proc_bar.get_height()\n","    ax.text(proc_bar.get_x(), height,\n","            f\"{height:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n","\n","ax.set_xticks(x)\n","\n","index_labels_plot2 = [\n","    \"Full_test_original_images\",\n","    \"Top_Original_Bottom_Generated\",\n","    \"Top_Generated_Bottom_Original\",\n","    \"Top_Processed_Bottom_Processed\"\n","]\n","ax.set_xticklabels(index_labels_plot2, rotation=5, ha='center')\n","ax.set_ylabel(\"Accuracy\")\n","ax.set_title(\"Classifier Accuracies by View Combination vs Training Percentage for $\\sigma_1(\\mathbf{C})<1$\")\n","ax.legend(title=\"Training %\")\n","plt.tight_layout()\n","plt.savefig(os.path.join(figures_base_dir_original, 'accuracy_comparison_eval.png'))\n","plt.show()"],"metadata":{"id":"o9DS7SME9yMV","executionInfo":{"status":"aborted","timestamp":1756242152477,"user_tz":-60,"elapsed":11130,"user":{"displayName":"Pavlos Tranakidis","userId":"11199795814834623818"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1sDFAyMslW7TuIKDl4wNCmB2APx-r-yeD","timestamp":1751576530741}],"authorship_tag":"ABX9TyMA1p13Da50XuN9/2GsM/un"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}